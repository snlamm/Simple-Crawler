This web crawler, built in Rails, works by taking the input of a web domain. It then renders a simple sitemap that consists of links to other pages within the same domain, links to external pages, and links to static content such as images and iframes.

A video demo of the rendered output can be found at: https://www.youtube.com/watch?v=dmJk62AbLfo&feature=youtu.be

Run this app by forking it, running rails s in the console, and navigating to http://localhost:3000/sitemap.

The crawler works by setting up a route in config/routes.rb, which maps to a controller action in app/controllers/sitemaps_controller.rb.

sitemaps_controller is responsible for retrieving the web crawler data and rendering it in app/views/sitemaps/show.html.erb.

The controller retrieves the appropriate data by calling upon the WebCrawlers class, which itself relies on the Link class and MapBuilder class.

The WebCrawlers class, housed in app/services/web_crawlers.rb, is in charge of storing the continuously growing site map data and keeping track of which pages have been visited.

The Link and MapBuilder classes are used within the WebCrawlers class to help simplify and accomplish these goals.

The Link class, at app/services/link.rb, stores the urls of each page in the web site and tracks which ones need to be visited or have been visited already.

The MapBuilder class, at app/adapters/map_builder.rb, is in charge of extracting and storing the desired data from each individual web page. This data is what is added to the WebCrawlers class's overall site map data. It is this site map data that, coming full circle, is eventually returned in the controller and rendered in the view template.

Each file mentioned has additional notes that go into more detail on a method-by-method basis.

Though Rails worked well for this project, it comes with a lot of bells and whistles that were unnecessary and cluttered the working space. As a result, I decided to delete a number of directories and files that come from generating a new Rails app. On the other hand, Rails grants a lot of flexibility in terms of adding new features, such as saving my scraping results to a database and manipulating them for further use.
